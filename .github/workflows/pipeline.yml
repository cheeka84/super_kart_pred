name: Super Kart Sales Prediction Pipeline

on:
  push:
    branches: [ main ]

jobs:

  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r super_kart_pred/requirements.txt
      - name: Upload dataset to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python super_kart_pred/model_building/data_register.py


  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r super_kart_pred/requirements.txt
      - name: Run data preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python super_kart_pred/model_building/prep.py


  model-training:
    needs: data-prep
    runs-on: ubuntu-latest
    env:
      MLFLOW_TRACKING_URI: http://127.0.0.1:5000
      MLFLOW_EXPERIMENT: SuperKart-Sales-Regression
      KEEP_ALIVE_SECONDS: "600"
      NGROK_AUTH_TOKEN: ${{ secrets.NGROK_AUTH_TOKEN }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies (+ mlflow + ngrok)
        run: |
          python -m pip install --upgrade pip
          pip install -r super_kart_pred/requirements.txt
          pip install mlflow pyngrok

      - name: Start MLflow UI
        run: |
          nohup mlflow ui --host 0.0.0.0 --port 5000 >/tmp/mlflow.log 2>&1 &
          for i in {1..10}; do
            if curl -fsS http://127.0.0.1:5000 >/dev/null; then
              echo "MLflow is up âœ…"
              break
            fi
            echo "Waiting for MLflow... ($i/10)"
            sleep 2
          done

      - name: Expose MLflow via ngrok (only if token present)
        run: |
          if [ -n "$NGROK_AUTH_TOKEN" ]; then
            python - <<'PY'
            import os
            from pyngrok import ngrok, conf
            conf.get_default().auth_token = os.environ["NGROK_AUTH_TOKEN"]
            url = ngrok.connect(5000, "http").public_url
            print("public_url="+url)
            with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                f.write(f"public_url={url}\n")
            PY
          else
            echo "NGROK_AUTH_TOKEN not set; skipping tunnel."
          fi

      - name: Show MLflow URL(s) and optional keep-alive
        run: |
          echo "Local MLflow:  http://127.0.0.1:5000"
          if [ -f "$GITHUB_OUTPUT" ] && grep -q '^public_url=' "$GITHUB_OUTPUT"; then
            PUB_URL=$(grep '^public_url=' "$GITHUB_OUTPUT" | tail -n1 | cut -d= -f2-)
            echo "Public MLflow: $PUB_URL"
            echo "Keeping alive for $KEEP_ALIVE_SECONDS seconds..."
            sleep "$KEEP_ALIVE_SECONDS"
          fi

      - name: Train model
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python super_kart_pred/model_building/train.py


  deploy-hosting:
    needs: [model-training, data-prep, register-dataset]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r super_kart_pred/requirements.txt
      - name: Push files to Frontend Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python super_kart_pred/hosting/hosting.py
